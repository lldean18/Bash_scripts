#!/bin/bash
# program to write the scripts to filter and combine multiple BAM files into a vcf file using ref_map.pl, and populations in STACKS,
# to filter the vcf file using vcf tools then use it to prepare a .xml file for SNAPP in BEAST
# written by Laura Dean Mon 26th Nov 18


####################################################################################################################################################################
####################################################################################################################################################################


# Set all the variables that must be specified in order in the input code used to run this code: bash make_SNAPP_analysis.sh followed by variables in order

# set the batch number
batchno=${1?Error: no batch number specified, please specify input variable 1, the batch number for this job}

# set the output shell file prefix
fileprefix=${2?Error: no output filename specified, please specify input variable 2, a name for the output file}

#set your working location
workinglocation=${3?Error: no working directory was set, please specify input variable 3, the path to your working directory}

# set the popmap filename prefix
popmap_prefix=${4?Error: please specify input variable 4, the prefix for the popmap file you will create}

# set the species table file prefix
species_prefix=${5?Error: please specify input variable 5, the prefix for the species table file you will create}

# set the constraints file prefix
constraints_prefix=${6?Error: please specify input variable 6, a file prefix for the constraints file you will create}

# set the starting tree prefix
starting_tree_prefix=${7?Error: please specify input variable 7, a file prefix for the starting tree file you will create}

# set the populations to be included in the analysis
pop1=${8?Error: please specify the first population to be included in the analysis}
pop2=${9?Error: please specify the second population to be included in the analysis}
pop3=${10?Error: please specify the third population to be included in the analysis}
pop4=${11?Error: please specify the fourth population to be included in the analysis}

# set the offset for divergence time calibration
cal_offset=${12:-0}

# set the mean divergence estimate for you divergence time calibration
cal_mean=${13?Error: please specify input variable 13, the mean divergence time estimate for your time calibration point}

# set the standard deviation of the mean of your divergence time calibration point
cal_SD=${14?Error: please specify input variable 14, the standard deviation (in real space) of the divergence time calibration point}

# set the list of populations excluding the outgroup
non_outgroup_pops=${15?Error: please specify input variable 15, a comma separated list of all populations in the analysis excluding the outgroup}

# set the SNAPP chain length
chain_length=${16?Error please specify input variable 16, the chain length for your SNAPP analysis}

# set the number of randomly selected snps you want to include in the SNAPP analysis
# this is done because it is hugely computationally expensive to run with lots of snps and not particularly any more accurate (Stange et al. 2018)
snp_no=${17?Error: please specify input variable 17, the number of snps you want to randomly filter from the data set to be used in the snapp analysis}

#set the snapps input xml and output file prefix
snapp_prefix=${18?Error: please specify input variable 18, the file prefix for the xml file generated by ruby for snapp input and the snapp output files}

#set the number of threads to use on your machine for the computationally intensive analyses
threads=${19?Error: please specify input variable 19, the number of threads you wish to use to perform your analysis}

#set the generation time for your species
g_time=${20?Error: please specify input variable 20, the generation time for your species}

# set the random number starting seed for randomly selecting the 1/3 of individuals to perform the analysis on
RANDOM=${21?Error: please specify input variable 21, the random number starting seed for randomly selecting the 1/3 of individuals to perform the analysis on}


# print the settings you just set to the screen
echo "
batch number is set to '$batchno'
the output shell fileprefix is set to '$fileprefix'
working location is set to '$workinglocation'
popmap file prefix is set to '$popmap_prefix'
species table file prefix is set to '$species_prefix'
constraints file prefix is set to '$constraints_prefix'
starting tree file prefix is set to '$starting_tree_prefix'
the populations to be included in this analysis are set to: '$pop1, $pop2, $pop3, $pop4'
offset for divergence time calibration is set to '$cal_offset'
mean divergence time for your calibration point is set to '$cal_mean'
standard deviation for your mean calibration point is set to '$cal_SD'
the non outgroup populations were set to '$non_outgroup_pops'
the chain length for the SNAPP analysis is set to '$chain_length'
the number of randomly selected snps to be used in the SNAPP analysis is set to '$snp_no'
the file prefix for the snapp input and output files is set to '$snapp_prefix'
the number of threads to use is set to '$threads'
the generation time for your study species is set to '$g_time'
the random number starting seed for selecting 1/3 individuals on which to perform the analysis is set to '$RANDOM'
"


########################################################################################
########################################################################################

# create the working directory if it doesnt already exist!
if [ -d $workinglocation ] ; then
echo "Working directory already exists so won't be created" ; else
mkdir $workinglocation
fi


####################################################################################################################################################################
####################################################################################################################################################################

# remove any previously written pop map so as not to duplicate information if the file is already written

if [ -f $workinglocation/$popmap_prefix.txt ] ; then
rm $workinglocation/$popmap_prefix.txt
fi

# remove any previously written species table file so as not to duplicate information if the file is already written

if [ -f $workinglocation/$species_prefix.txt ] ; then
rm $workinglocation/$species_prefix.txt
fi

# remove any previously written pops_for_tree.txt file so as not to duplicate information if the file is already written
if [ -f $workinglocation/pops_for_tree.txt ] ; then
rm $workinglocation/pops_for_tree.txt
fi

# write the popmap, species table and pops_for_tree.txt files
# at the moment the 4 populations must be specified here in this file as I can't seem to take a previously defined variable into this for loop

files=(/home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/Isabels_data/BAM_files/$pop1*.bam \
/home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/Isabels_data/BAM_files/$pop2*.bam \
/home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/Isabels_data/BAM_files/$pop3*.bam \
/home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/Isabels_data/BAM_files/$pop4*.bam)

echo "There are ${#files[@]} total individuals in the populations you have selected"

# set the proportion of the files you want to sample each time by setting the 'take' variable
take=$((1*${#files[@]}/3))

#sample individuals without replacement (so you dont get sequences from the same individual twice)
#RANDOM=12345; echo random number seed set to $RANDOM
while ((i < $take))
do
	r=$((RANDOM%${#files[@]}))
	f=${files[r]}
	if [[ -n $f ]]
	then
		i=$((i+1))
		for file in $f
			do
			fishname=${file:81:10} # extract the individual names from the filenames
			popname=${file:81:4} # extract the population names from the filenames
			echo "$fishname	$popname" >>$workinglocation/$popmap_prefix.txt
			echo "$popname $fishname" >>$workinglocation/$species_prefix.txt
			echo "$fishname" >>$workinglocation/pops_for_tree.txt
			echo "Individual to randomly be included (~1/3 of your individuals will be randomly selected): $fishname"
			done
		unset files[r]
	fi
done

echo "
Popmap file written"
echo "Species table file written"
echo "pops_for_tree file written
"

# remove the poorly sequenced BEPA150845 individual from the popmap, species table and pops_for_tree files if it has been randomly selected for inclusion in the analysis

sed -i '/BEPA150845/d' /$workinglocation/$popmap_prefix.txt
sed -i '/BEPA150845/d' /$workinglocation/$species_prefix.txt
sed -i '/BEPA150845/d' /$workinglocation/pops_for_tree.txt

echo "individual BEPA150845 removed from popmap file because of poor sequence coverage"
echo "individual BEPA150845 removed from species table because of poor sequence coverage"
echo "individual BEPA150845 removed from pops_for_tree file because of poor sequence coverage
"

####################################################################################################################################################################
####################################################################################################################################################################

# remove any previously written constraints file so as not to duplicate information if the file is already written

if [ -f $workinglocation/$constraints_prefix.txt ] ; then
rm $workinglocation/$constraints_prefix.txt
fi

# write the constraints file

echo "lognormal($cal_offset,$cal_mean,$cal_SD)	stem	$non_outgroup_pops
">>$workinglocation/$constraints_prefix.txt

echo "Constraints file written"

####################################################################################################################################################################
####################################################################################################################################################################

# remove any previously written starting tree file so as not to duplicate information if the file is already written

if [ -f $workinglocation/$starting_tree_prefix.txt ] ; then
rm $workinglocation/$starting_tree_prefix.txt
fi

# write the starting tree file
echo "($pop1,($pop4,($pop3,$pop2)));">>$workinglocation/$starting_tree_prefix.txt

echo "Starting tree file written
"

####################################################################################################################################################################
####################################################################################################################################################################


# remove any previously written output shell file so as not to duplicate information if the file is already written

if [ -f /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh ] ; then
rm /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh
fi

# write the information to the top of the file
echo "# running this file takes raw bam files and processes them into an xml file to be input into a SNAPP analysis in BEAST
# this file is created by running the make_SNAPP_analysis.sh file

">> /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

# move to the snapp analysis working directory
#echo "#move to the SNAPP analysis working directory
#cd /home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/my_RAD_analysis/SNAPP_analysis
#">> /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

#print the instructions to remove any previously generated ref_map files
echo "# remove any previously generated ref_map files in the working directory (as otherwise populations will not run as it won't know which ones to use
rm $workinglocation/$pop1* $workinglocation/$pop2* $workinglocation/$pop3* $workinglocation/$pop4*
">> /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "instructions to remove previously generated ref_map files printed to $fileprefix.sh file"

#print the ref_map.pl parameters
echo "
# run the ref_map.pl program in STACKS to call all of the BAM files into a single file
# begin ref_map.pl
ref_map.pl \
-b $batchno \
-T $threads \
-O $workinglocation/$popmap_prefix.txt \
-o $workinglocation \
--samples /home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/Isabels_data/BAM_files \
-S \
-m 3" >>/home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "ref_map.pl instructions printed to $fileprefix.sh bash file"


#####################################################################################


#print the populations parameters
echo "
# run the populations program in the STACKS pipeline to filter the data and output a vcf file
# begin populations
populations \
-P $workinglocation \
--popmap $workinglocation/$popmap_prefix.txt \
-t $threads \
-O $workinglocation \
-b $batchno \
--min_maf 0.05 \
-p 4 \
-r 0.8 \
--vcf \
--vcf_haplotypes \
--ordered_export \
--write_single_snp" >>/home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "populations instructions printed to $fileprefix.sh bash file"


#####################################################################################


# print the instructions to filter the vcf file to remove the sex chromosomes and thin to unlinked loci
echo "
# filter the VCF file to remove the sex chromosomes and thin to unlinked loci
vcftools \
--vcf $workinglocation/batch_$batchno.vcf \
--out $workinglocation/batch_$batchno.filtered \
--not-chr groupIX \
--not-chr groupXIX \
--min-meanDP 6 \
--max-meanDP 200 \
--max-missing 0.75 \
--thin 10000 \
--mac 2 \
--recode \
--recode-INFO-all">>/home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "instructions for sex chromosome removal using VCFtools printed to $fileprefix.sh bash file"


#####################################################################################


# print the instructions to print the filter summary of the vcf file filtering
echo "
# print the filter summary of the vcf file filtering
vcftools \
--vcf $workinglocation/batch_$batchno.vcf \
--out $workinglocation/batch_$batchno.filtered \
--not-chr groupIX \
--not-chr groupXIX \
--min-meanDP 6 \
--max-meanDP 200 \
--max-missing 0.75 \
--thin 10000 \
--mac 2 \
--FILTER-summary">>/home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "instructions for vcf filtering log to be created printed to $fileprefix.sh bash file"


#####################################################################################

# print the instructions to remove any previously written xml file so as not to duplicate information if the file is already written

echo "
# remove any previously written xml file so as not to duplicate information if the file is already written
if [ -f $workinglocation/$snapp_prefix.xml ] ; then
rm $workinglocation/$snapp_prefix.xml
fi">>/home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

#####################################################################################

# print the instructions to copy the ruby script to the working directiry if it isnt there
echo "# copy the ruby script to the working directory if it doesnt already exist!
if [ -f $workinglocation/snapp_prep_LD.rb ] ; then
; else
cp /home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/my_RAD_analysis/SNAPP_analysis/snapp_prep_LD.rb $workinglocation
fi
" >>/home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

######################################################################################

#print the ruby file preperation script
echo "
# run the ruby file preperation script
ruby $workinglocation/snapp_prep_LD.rb \
--vcf $workinglocation/batch_$batchno.filtered.recode.vcf \
--table $workinglocation/$species_prefix.txt \
--constraints $workinglocation/$constraints_prefix.txt \
--starting-tree $workinglocation/$starting_tree_prefix.txt \
-m $snp_no \
--length $chain_length \
--xml $workinglocation/$snapp_prefix.xml \
--out $snapp_prefix
" >> /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "ruby file preparation instructions printed to $fileprefix.sh bash file"

#####################################################################################

# print the instructions to start BEAST
echo "# start the beast analysis
java -Dbeast.load.jars=true -jar /home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/my_RAD_analysis/SNAPP_analysis/beast/lib/beast.jar \
-threads $threads \
-working $workinglocation \
$workinglocation/$snapp_prefix.xml
" >> /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "instructions to start beast with a user response of yes printed to $fileprefix.sh bash file"

######################################################################################

# print the instructions to add the population size estimates to the beast log file
echo "# run the ruby script which adds the population size estimates to the beast log files
ruby /home/mbzlld/lauras_files/Post-doc_work_2018/RAD_analysis/my_RAD_analysis/SNAPP_analysis/add_theta_to_log_LD.rb \
-l $workinglocation/$snapp_prefix.log \
-t $workinglocation/$snapp_prefix.trees \
-g $g_time \
-o $workinglocation/$snapp_prefix.popsize.log
" >> /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "instructions to add the population size estimates to the beast log file"

########################################################################################

#create the burnin variable outside of the echo quotations
treeannotator_burnin=$(($chain_length/50/10/2))

# print the instructions to run treeannotator to add the posterior probabilities to branch nodes
echo "# run treeannotator to add the posterior probabilities to branch nodes
treeannotator \
-heights mean \
-burnin $treeannotator_burnin \
$workinglocation/$snapp_prefix.trees \
$workinglocation/$snapp_prefix.tre
" >> /home/mbzlld/lauras_files/Post-doc_work_2018/my_BASH_scripts/$fileprefix.sh

echo "instructions to run tree annotator to add posterior probabilities to .tre file printed to the $fileprefix.sh bash file"

